{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Lane Finding\n",
    "In this notebook I will run the experiments included\n",
    "in the report.\n",
    "\n",
    "## Pipeline\n",
    "\n",
    "First I project the image using a calibrated camera. I then find\n",
    "the binary image highlighting lanes using sobel edge detection\n",
    "and color thresholding in HLS space. The binary image of the lanes\n",
    "is then projected to a birds eye view. I apply a sliding window\n",
    "across the left and right lanes starting at the histogram peeks\n",
    "in the bottom of the image. I then fit a second degree polynomial \n",
    "to the detected points. The detection is smoothed and corrected\n",
    "accross frames.\n",
    "\n",
    "\n",
    "## Implementation\n",
    "\n",
    "I implement the processing pipeline in my library `lib_lanes` in the\n",
    "folder with the same name:\n",
    "\n",
    "+ `cameras.py`: Contains a class for a calibrated camera.\n",
    "+ `perspective.py`: A perspective transform to compute the birdseye view.\n",
    "+ `thresholding.py`: Compute binary images based on color thresholding and sobel edge detection.\n",
    "+ `lane_detector.py`: Detect lanes using a sliding window and polynomial line fitting.\n",
    "+ `smooth.py`: Smooth lane detection in videos and reject results based on curvature.\n",
    "+ `pipeline.py`: Run the pipeline on a video.\n",
    "\n",
    "In the following I will provide examples of the pipeline components and compute the final video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib_lanes.thresholding import *\n",
    "from lib_lanes.perspective import *\n",
    "from lib_lanes.cameras import *\n",
    "from lib_lanes.pipeline import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Camera Calibration\n",
    "\n",
    "The calibration works by detecting corners in the source images first and mapping\n",
    "them onto a square grid. We then use the calibration funciton to calculate the\n",
    "camera matrix and calculate the distortion. Using both we can undistort images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = CalibratedCamera.from_images(\"camera_cal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calibrate_folder(inf, outf):\n",
    "    for img in os.listdir(inf):\n",
    "        filename = img.split(\".\")[0]\n",
    "        img   = mpimg.imread(\"{}/{}\".format(inf, img))\n",
    "        calib = camera.undistort(img)\n",
    "        plt.figure(figsize=(50, 10))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(calib)\n",
    "        plt.savefig('{}/calib_{}.png'.format(outf, filename))\n",
    "        plt.close()\n",
    "    \n",
    "calibrate_folder('camera_cal', 'output_images')\n",
    "calibrate_folder('test_images', 'output_images')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see in the test images, we successfull removed the distortion from the checker board.\n",
    "The original image is shown on the left and the undistorted image on the right.\n",
    "<img src=\"output_images/calib_calibration1.png\" border=1/>\n",
    "\n",
    "We now can apply the code to one of our test images. Again, the original image is shown on the left and the undistorted image on the right.\n",
    "\n",
    "<img src=\"output_images/calib_test6.png\" border=1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Thresholding\n",
    "\n",
    "We binarize images by applying a threshold to the x component of the image\n",
    "and the saturatoin component of the hls color space. We combine the binary\n",
    "images by adding the results together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "binarizer = BinaryConverter(120, 255, 50, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_folder(inf, outf):\n",
    "    for img in os.listdir(inf):\n",
    "        filename = img.split(\".\")[0]\n",
    "        path     = \"{}/{}\".format(inf, img)\n",
    "        img      = mpimg.imread(path)\n",
    "        undist   = camera.undistort(img)\n",
    "        s        = binarizer.binary_hls(undist)\n",
    "        x        = binarizer.binary_sobel(undist)\n",
    "        binarize = binarizer.convert(undist)\n",
    "        plt.figure(figsize=(50, 10))\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.imshow(undist)\n",
    "        plt.subplot(1, 4, 2)\n",
    "        plt.imshow(s)\n",
    "        plt.subplot(1, 4, 3)\n",
    "        plt.imshow(x)\n",
    "        plt.subplot(1, 4, 4)\n",
    "        plt.imshow(binarize, cmap='gray')\n",
    "        plt.savefig('{}/binary_{}.png'.format(outf, filename))\n",
    "        plt.close()\n",
    "        \n",
    "binarize_folder('test_images', 'output_images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lines show up nicely in the combined image. From left to right we see\n",
    "the undistorted image, the saturation thresholded image, the sobel thresholded\n",
    "images and the combined image.\n",
    "\n",
    "<img src=\"output_images/binary_test2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Projective Transform\n",
    "\n",
    "In order to find the lanes, we transform the image into a birdseye view. We get points on the undistorted\n",
    "image forming a trapezoid on top of the lanes. We then find a transform that maps the lanes ontop a square\n",
    "resulting in the birds eye view. In the end we are projecting the binary image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "projection = BirdsEyeView(720, 1280, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_folder(inf, outf):\n",
    "    for img in os.listdir(inf):\n",
    "        filename = img.split(\".\")[0]\n",
    "        path     = \"{}/{}\".format(inf, img)\n",
    "        img      = mpimg.imread(path)\n",
    "        undist   = camera.undistort(img)\n",
    "        binarize = binarizer.convert(undist)\n",
    "        project_img = projection.project(undist)\n",
    "        project_bin = projection.project(binarize)\n",
    "\n",
    "        plt.figure(figsize=(50, 10))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(undist)\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(project_img)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(project_bin)\n",
    "        plt.savefig('{}/projection_{}.png'.format(outf, filename))\n",
    "        plt.close()\n",
    "        \n",
    "project_folder('test_images', 'output_images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As one can see we successfully map the images to the birdseye view.\n",
    "\n",
    "<img src=\"output_images/projection_test3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Lane detectors\n",
    "\n",
    "we first start by using the histogram method to find the two lanes at the bottom of the page. We then shift a sliding window along each line. The next center of the window is the mean of the x positions in the last window.\n",
    "We then fit a polynomial to the left and right lane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_folder(inf, outf):\n",
    "    for img in os.listdir(inf):\n",
    "        pipeline = Pipeline()\n",
    "        filename = img.split(\".\")[0]\n",
    "        path     = \"{}/{}\".format(inf, img)\n",
    "        img      = mpimg.imread(path)\n",
    "        debug    = pipeline.process_image(img, True)\n",
    "        highlighted = pipeline.process_image(img, False)\n",
    "\n",
    "        plt.figure(figsize=(50, 10))\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(debug)\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(highlighted)\n",
    "\n",
    "        plt.savefig('{}/pipeline_{}.png'.format(outf, filename))\n",
    "        plt.close()\n",
    "        \n",
    "detect_folder('test_images', 'output_images/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the windows along the left and right lane highlighted in green. We then use the polynomial\n",
    "fit to generate the x positions for all y positions in the image. The results are marked up in red (center image).\n",
    "Ones the lines are found we can make a mask in the birds eye view space and project it back onto the real image\n",
    "(right image). We can calculate the curvature by using the computed x and y positions scaled to meters (estimating the distances of the trapezoid from the image). For the center lane, we compute the center lane as the mid points of the left and right lane and the center points of the trapezoid. We then calculate the root mean square error.\n",
    "The center lane of the trapezoid is shown in \"white\" and the center lane is marked in red. \n",
    "<img src=\"output_images/pipeline_test2.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Video\n",
    "\n",
    "We can now compute the output video. We average the result of the last 6 lane\n",
    "detections and reject lane detections with an unrealistic curavture ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "t:   0%|          | 0/1260 [00:00<?, ?it/s, now=None]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video output.mp4.\n",
      "Moviepy - Writing video output.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready output.mp4\n"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "pipeline = Pipeline()\n",
    "clip = VideoFileClip(\"project_video.mp4\")\n",
    "processed = clip.fl_image(pipeline.process_image)\n",
    "processed.write_videofile(\"output.mp4\", audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"960\" height=\"540\" controls>\n",
       "  <source src=\"output.mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"output.mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_statistics = pd.read_csv(\"log.csv\")\n",
    "plt.plot(track_statistics['curvature'])\n",
    "plt.xlabel('frame')\n",
    "plt.ylabel('radius [m]')\n",
    "plt.savefig('output_images/curvature.png')\n",
    "plt.close()\n",
    "\n",
    "plt.plot(track_statistics[' distance'])\n",
    "plt.ylabel('distance [m]')\n",
    "plt.xlabel('frame')\n",
    "plt.savefig('output_images/distance.png')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"output_images/curvature.png\"/>\n",
    "<img src=\"output_images/distance.png\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
